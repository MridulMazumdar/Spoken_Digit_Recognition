{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCa9EH0bXRly",
    "outputId": "61505666-0758-423f-dbbc-f8bdabc760c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwoTWIysaNmc"
   },
   "source": [
    "<pre><font size=6>Spoken Digit Recognition</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPO3mjDDaNmf"
   },
   "source": [
    "<pre>\n",
    "In this notebook, You will do Spoken Digit Recognition. \n",
    "\n",
    "Input - speech signal, output - digit number\n",
    "It contains  \n",
    "\n",
    "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
    "2. Training the LSTM with RAW data\n",
    "3. Converting to spectrogram and Training the LSTM network\n",
    "4. Creating the augmented data and doing step 2 and 3 again.  \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRqlNwOjvQIl"
   },
   "outputs": [],
   "source": [
    "!pip3 install tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_qGuPcj-aNmh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "##if you need any imports you can do that here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdhFzGK1aNmo"
   },
   "source": [
    "We shared recordings.zip, please unzip those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HDBcl_PUaNmp"
   },
   "outputs": [],
   "source": [
    "#read the all file names in the recordings folder given by us\n",
    "#(if you get entire path, it is very useful in future)\n",
    "#save those files names as list in \"all_files\"\n",
    "all_files=os.listdir('/content/drive/MyDrive/Spoken_digit_assignment/recordings/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhvSIN6raNm3"
   },
   "source": [
    "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "You can get the label from the first letter of name.  \n",
    "Eg: 0_jackson_0 --> 0  \n",
    "0_jackson_43 --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fWP6vXBeaNm3"
   },
   "outputs": [],
   "source": [
    "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#You can get the label from the first letter of name.  \n",
    "#Eg: 0_jackson_0 --> 0  \n",
    "#0_jackson_43 --> 0\n",
    "dir='/content/drive/MyDrive/Spoken_digit_assignment/recordings/'\n",
    "label=[]\n",
    "path=[]\n",
    "for f in all_files:\n",
    "  path.append(dir+f)\n",
    "  \n",
    "  x=f.split('_')\n",
    "  label.append(int(x[0]))\n",
    "\n",
    "df_audio=pd.DataFrame({'path':path,'label':label})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85M-hwFFb0In",
    "outputId": "51614b23-8824-4bba-cb9f-f36d5f170afc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio['label'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZpuaGuJaNm8",
    "outputId": "641cf36b-e96b-4076-be99-cb3e64fc8eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2000 non-null   object\n",
      " 1   label   2000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PlfssCc3aNnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ448aENaNnR"
   },
   "source": [
    "<pre><font size=4>Train and Validation split</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vSPy-Ln6aNnS"
   },
   "outputs": [],
   "source": [
    "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
    "#use stratify sampling\n",
    "#use random state of 45\n",
    "#use test size of 30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df_audio['path']\n",
    "Y=df_audio['label']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.3,random_state=45,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGhh-39vaNnb"
   },
   "source": [
    "<pre><font size=4>Preprocessing</font>\n",
    "\n",
    "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "i99JacQSaNnc"
   },
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(samples, sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rx97f8GGaNnh",
    "outputId": "e8d209e1-b2d0-40d6-def6-bd7501b7dbdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:32<00:00, 42.61it/s]\n",
      "100%|██████████| 600/600 [00:13<00:00, 43.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#use load_wav function that was written above to get every wave. \n",
    "#save it in X_train_processed and X_test_processed\n",
    "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n",
    "from tqdm import tqdm\n",
    "train_samples=[]\n",
    "train_duration=[]\n",
    "test_samples=[]\n",
    "test_duration=[]\n",
    "\n",
    "for f in tqdm(X_train):\n",
    "  train_samples.append(load_wav(f)[0])\n",
    "  train_duration.append(load_wav(f)[1])\n",
    "\n",
    "for f in tqdm(X_test):    \n",
    "  test_samples.append(load_wav(f)[0])\n",
    "  test_duration.append(load_wav(f)[1])\n",
    "\n",
    "X_train_processed = pd.DataFrame({'raw_data':train_samples,\n",
    "                               'duration':train_duration})\n",
    "\n",
    "X_test_processed = pd.DataFrame({'raw_data':test_samples,\n",
    "                               'duration':test_duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "duQZPQevaNno",
    "outputId": "15727f4c-843d-4c60-b72c-800040b4b919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe412cc2750>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the histogram of the duration for trian\n",
    "X_train_processed['duration'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvLhm1AqaNny",
    "outputId": "a2fcef49-74ca-4305-9971-f4f665535494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th percentile is  0.1435374149659864\n",
      "10th percentile is  0.26312925170068024\n",
      "20th percentile is  0.30006349206349203\n",
      "30th percentile is  0.33207256235827665\n",
      "40th percentile is  0.3590839002267574\n",
      "50th percentile is  0.3902947845804989\n",
      "60th percentile is  0.41811337868480725\n",
      "70th percentile is  0.44597732426303854\n",
      "80th percentile is  0.4816326530612245\n",
      "90th percentile is  0.5533106575963719\n",
      "100th percentile is  2.195918367346939\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "for i in range(0,110,10):\n",
    "  print(str(i)+'th percentile is ',np.percentile(X_train_processed['duration'],q=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSlVQh4CaNn2",
    "outputId": "b3afe34c-01f6-45fb-8a47-9a47396eedf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th percentile is  0.5533106575963719\n",
      "91th percentile is  0.5669832199546486\n",
      "92th percentile is  0.5794503401360545\n",
      "93th percentile is  0.5985732426303856\n",
      "94th percentile is  0.611208163265306\n",
      "95th percentile is  0.6227800453514739\n",
      "96th percentile is  0.6366947845804989\n",
      "97th percentile is  0.6587115646258503\n",
      "98th percentile is  0.6838566893424036\n",
      "99th percentile is  0.784215873015873\n",
      "100th percentile is  2.195918367346939\n"
     ]
    }
   ],
   "source": [
    "##print 90 to 100 percentile values with step size of 1. \n",
    "for i in range(90,101):\n",
    "  print(str(i)+'th percentile is ',np.percentile(X_train_processed['duration'],q=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cux3_jfcaNoM"
   },
   "source": [
    "<pre>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset. \n",
    "\n",
    "While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
    "\n",
    "Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
    "\n",
    "Also create a masking vector for train and test. \n",
    "\n",
    "masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDnMIEJVgfhz",
    "outputId": "ee8d03f9-f1f7-4984-f972-c742791c96e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "voqSEyvcaNoO"
   },
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "B1-_r20BaNoW"
   },
   "outputs": [],
   "source": [
    "## as discussed above, Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
    "## save in the X_train_pad_seq, X_test_pad_seq\n",
    "## also Create masking vector X_train_mask, X_test_mask\n",
    "## all the X_train_pad_seq, X_test_pad_seq, X_train_mask, X_test_mask will be numpy arrays mask vector dtype must be bool.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def create_mask(x):\n",
    "   if len(x)<max_length:\n",
    "     return [*[1]*len(x),*[0]*(max_length-len(x))]\n",
    "   else:\n",
    "     return [*[1]*max_length]\n",
    "                                                                                                                                                                  \n",
    "                                                                              \n",
    "\n",
    "X_train_pad_seq= np.array(pad_sequences(X_train_processed['raw_data'], dtype='float32', padding='post',maxlen=max_length))\n",
    "X_test_pad_seq= np.array(pad_sequences(X_test_processed['raw_data'], dtype=\"float32\", padding='post', maxlen=max_length))\n",
    "\n",
    "X_train_mask= np.array([create_mask(i) for i in X_train_processed['raw_data']],dtype=bool)\n",
    "X_test_mask= np.array([create_mask(i) for i in X_test_processed['raw_data'] ],dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHHsoPfGCMRH",
    "outputId": "120ce45e-965f-40bf-81a5-acbc4b50da33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 17640)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kaYQ1jaNop"
   },
   "source": [
    "### 1. Giving Raw data directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGHxh3jTaNoq"
   },
   "source": [
    "<pre>\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
    "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
    "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). \n",
    "3. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
    "4. make sure that it won't overfit. \n",
    "5. You are free to include any regularization\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "X8yg951AaNor"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense,Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "d8y1sgeVaNoy"
   },
   "outputs": [],
   "source": [
    "## as discussed above, please write the LSTM\n",
    "In=Input(shape=(max_length,1))\n",
    "In2=Input(shape=(max_length),dtype=bool)\n",
    "LS=LSTM(50)(In,mask=In2)\n",
    "D1=Dense(32,activation='relu')(LS)\n",
    "OUT=Dense(10,activation='softmax')(D1)\n",
    "model=Model(inputs=([In,In2]),outputs=OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXfUaoAgYUA7",
    "outputId": "8ce00e4b-83f0-4916-d31d-7d51ce9fd59b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 17640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 17640)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 50)           10400       input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           1632        lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           330         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,362\n",
      "Trainable params: 12,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "R5g3V0c-IUGC"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "L7fwPZy8xHq_"
   },
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "      self.val_f1 = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      val_predict = (np.asarray(self.model.predict([X_test_pad_seq,X_test_mask]))).round()\n",
    "      \n",
    "      digit_predict=[]\n",
    "      \n",
    "      for i in val_predict:\n",
    "        digit_predict.append(np.argmax(i))\n",
    "      val_targ = y_test\n",
    "      \n",
    "      f1 = f1_score(val_targ, digit_predict,average='micro')\n",
    "      \n",
    "      self.val_f1.append(f1)\n",
    "      \n",
    "      print(\" Micro_f1_score:\",f1)\n",
    "        \n",
    "metrics = Metrics()\n",
    "logdir='/content/drive/MyDrive/Spoken_digit_assignment/logs/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir,)\n",
    " \n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_acc',mode='max',patience=2)\n",
    "\n",
    "optim=tf.keras.optimizers.Adam()\n",
    "\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model.compile(optimizer=optim,loss=loss,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "jLaUY8zQCpK3"
   },
   "outputs": [],
   "source": [
    "X_train_full=[X_train_pad_seq,X_train_mask]\n",
    "\n",
    "X_test_full=[X_test_pad_seq,X_test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2qCaU9SY1hD",
    "outputId": "c12829dc-30ed-4100-ca93-99ea3c424dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.3026 - acc: 0.1007 Micro_f1_score: 0.10000000000000002\n",
      "14/14 [==============================] - 18s 1s/step - loss: 2.3026 - acc: 0.1007 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.3026 - acc: 0.1007 Micro_f1_score: 0.10000000000000002\n",
      "14/14 [==============================] - 14s 997ms/step - loss: 2.3026 - acc: 0.1007 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.3026 - acc: 0.1007 Micro_f1_score: 0.10000000000000002\n",
      "14/14 [==============================] - 14s 994ms/step - loss: 2.3026 - acc: 0.1007 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2dcaec690>"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_full,y_train,validation_data=[X_test_full,y_test],epochs=20,batch_size=100,\n",
    "          callbacks=[tensorboard,early_stopping,metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fwk0X4zaNpR"
   },
   "source": [
    "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
    "<pre>\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
    "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nb5AGzTjaNpS"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "B__rN4RjaNpc"
   },
   "outputs": [],
   "source": [
    "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
    "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
    "X_train_spectrogram=[]\n",
    "for i in X_train_pad_seq:\n",
    "  X_train_spectrogram.append(convert_to_spectrogram(i))\n",
    "X_train_spectrogram=np.array(X_train_spectrogram,dtype='float')\n",
    "\n",
    "X_test_spectrogram=[]\n",
    "for i in X_test_pad_seq:\n",
    "  X_test_spectrogram.append(convert_to_spectrogram(i))\n",
    "X_test_spectrogram=np.array(X_test_spectrogram,dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxlEVyIYaNpt"
   },
   "source": [
    "<pre>\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_spectrogram and y_train  \n",
    "Test data: X_test_spectrogram and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
    "2. Average the output of every time step and give this to the Dense layer of any size. \n",
    "(ex: Output from LSTM will be  (#., time_steps, features) average the output of every time step i.e, you should get (#.,time_steps) \n",
    "and then pass to dense layer )\n",
    "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
    "4. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IaQjaiiGaNpv"
   },
   "outputs": [],
   "source": [
    "logdir='/content/drive/MyDrive/Spoken_digit_assignment/model2_logs/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cNv7_Y9jVoz",
    "outputId": "20582c12-4f67-4c2d-ea84-08f0c526134b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 64, 35)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "862fP2e-aNp3"
   },
   "outputs": [],
   "source": [
    "\n",
    "In=Input(shape=(64,35,))\n",
    "\n",
    "LS=LSTM(units=100,return_sequences=True)(In)\n",
    "\n",
    "output=tf.keras.layers.Reshape(target_shape=(64,100,1))(LS)\n",
    "\n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAveragePooling1D())(output)\n",
    "\n",
    "output=tf.keras.layers.Reshape(target_shape=(64,))(output)\n",
    "\n",
    "output=Dense(128,activation='relu')(output)\n",
    "\n",
    "output=Dense(64,activation='relu')(output)\n",
    "\n",
    "predict=Dense(10,activation='softmax')(output)\n",
    "\n",
    "model2=Model(inputs=In,outputs=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtMsbGs3aNp_",
    "outputId": "b3ed36ac-40b9-4852-f5e2-61393feee8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 64, 35)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 64, 100)           54400     \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 64, 100, 1)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 64, 1)             0         \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 71,626\n",
      "Trainable params: 71,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kY6y-Xiemyrj",
    "outputId": "751e973f-1d12-448d-aa26-ac79936452aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 64, 35)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "mveFGwr7kHPj"
   },
   "outputs": [],
   "source": [
    "optim=tf.keras.optimizers.Adam()\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model2.compile(optimizer=optim,loss=loss,metrics=['acc'])\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_acc',patience=3,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "aRfn20Z0CsAo"
   },
   "outputs": [],
   "source": [
    "y_train=np.array(y_train,dtype='float')\n",
    "y_test=np.array(y_test,dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xx4rrSwwI7tx",
    "outputId": "f30f9ecd-2be8-4b2f-b9fe-b6efad35b2aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 64, 35)"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6dNtZINkhar",
    "outputId": "04a9b63b-4718-4da3-f4f7-d19eca22f8a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 2.3027 - acc: 0.1150WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0088s vs `on_train_batch_end` time: 0.1513s). Check your callbacks.\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.2972 - acc: 0.1340Micro f1 score: 0.10000000000000002\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 2.2898 - acc: 0.1571 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.2377 - acc: 0.2090Micro f1 score: 0.10000000000000002\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 2.2130 - acc: 0.2143 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.0760 - acc: 0.3280Micro f1 score: 0.10499999999999998\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 2.0512 - acc: 0.3179 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.8403 - acc: 0.3720Micro f1 score: 0.12333333333333335\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.8038 - acc: 0.3900 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.5897 - acc: 0.4010Micro f1 score: 0.13833333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.5534 - acc: 0.4271 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.3985 - acc: 0.4950Micro f1 score: 0.26166666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.3745 - acc: 0.5107 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.2485 - acc: 0.5680Micro f1 score: 0.3333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.2332 - acc: 0.5836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.1216 - acc: 0.6130Micro f1 score: 0.3933333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.1252 - acc: 0.6079 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.0456 - acc: 0.6700Micro f1 score: 0.44166666666666665\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0255 - acc: 0.6707 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.9763 - acc: 0.6611Micro f1 score: 0.5033333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.9625 - acc: 0.6643 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.9182 - acc: 0.6860Micro f1 score: 0.5033333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.9049 - acc: 0.6921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.8393 - acc: 0.7420Micro f1 score: 0.5633333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.8375 - acc: 0.7364 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.7750 - acc: 0.7344Micro f1 score: 0.635\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.7656 - acc: 0.7486 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.7387 - acc: 0.7600Micro f1 score: 0.6516666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.7118 - acc: 0.7721 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.6936 - acc: 0.7860Micro f1 score: 0.685\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.7058 - acc: 0.7814 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.6560 - acc: 0.7920Micro f1 score: 0.7166666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.6598 - acc: 0.7871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.6183 - acc: 0.7844Micro f1 score: 0.7283333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.6142 - acc: 0.7864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.5893 - acc: 0.8010Micro f1 score: 0.765\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5719 - acc: 0.8064 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5382 - acc: 0.8244Micro f1 score: 0.7666666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5399 - acc: 0.8207 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.5288 - acc: 0.8340Micro f1 score: 0.7566666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5140 - acc: 0.8350 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.5179 - acc: 0.8280Micro f1 score: 0.7816666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.5116 - acc: 0.8264 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4850 - acc: 0.8340Micro f1 score: 0.78\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4784 - acc: 0.8400 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4591 - acc: 0.8370Micro f1 score: 0.7883333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4617 - acc: 0.8393 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4501 - acc: 0.8470Micro f1 score: 0.7966666666666665\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4516 - acc: 0.8471 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4424 - acc: 0.8420Micro f1 score: 0.7883333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4401 - acc: 0.8443 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4226 - acc: 0.8500Micro f1 score: 0.7816666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4408 - acc: 0.8371 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4606 - acc: 0.8467Micro f1 score: 0.8000000000000002\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4413 - acc: 0.8557 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3995 - acc: 0.8650Micro f1 score: 0.8133333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4059 - acc: 0.8686 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3876 - acc: 0.8690Micro f1 score: 0.8066666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3828 - acc: 0.8721 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3874 - acc: 0.8640Micro f1 score: 0.8316666666666667\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.3697 - acc: 0.8714 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3553 - acc: 0.8822Micro f1 score: 0.8383333333333334\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.3523 - acc: 0.8836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3480 - acc: 0.8830Micro f1 score: 0.8316666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3443 - acc: 0.8786 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3344 - acc: 0.8900Micro f1 score: 0.8233333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3404 - acc: 0.8864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3457 - acc: 0.8789Micro f1 score: 0.825\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3433 - acc: 0.8843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3298 - acc: 0.8900Micro f1 score: 0.8366666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3336 - acc: 0.8936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3067 - acc: 0.8889Micro f1 score: 0.8466666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3127 - acc: 0.8929 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3127 - acc: 0.9044Micro f1 score: 0.8533333333333335\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3028 - acc: 0.9093 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3018 - acc: 0.9020Micro f1 score: 0.8466666666666667\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2993 - acc: 0.9029 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3072 - acc: 0.9089Micro f1 score: 0.845\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2899 - acc: 0.9129 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2837 - acc: 0.9067Micro f1 score: 0.8433333333333335\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3040 - acc: 0.8986 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2907 - acc: 0.9156Micro f1 score: 0.8666666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2894 - acc: 0.9100 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2690 - acc: 0.9190Micro f1 score: 0.855\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2711 - acc: 0.9143 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2609 - acc: 0.9067Micro f1 score: 0.885\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2640 - acc: 0.9121 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2549 - acc: 0.9156Micro f1 score: 0.88\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2508 - acc: 0.9207 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2513 - acc: 0.9278Micro f1 score: 0.8733333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2451 - acc: 0.9271 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2363 - acc: 0.9290Micro f1 score: 0.8916666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2357 - acc: 0.9279 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2261 - acc: 0.9200Micro f1 score: 0.8633333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2257 - acc: 0.9307 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2132 - acc: 0.9430Micro f1 score: 0.88\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2175 - acc: 0.9421 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2235 - acc: 0.9350Micro f1 score: 0.8633333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2329 - acc: 0.9286 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2564 - acc: 0.9200Micro f1 score: 0.875\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2410 - acc: 0.9286 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2265 - acc: 0.9370Micro f1 score: 0.8766666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2154 - acc: 0.9364 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2041 - acc: 0.9430Micro f1 score: 0.8816666666666667\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2100 - acc: 0.9429 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2061 - acc: 0.9350Micro f1 score: 0.895\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2086 - acc: 0.9343 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2026 - acc: 0.9400Micro f1 score: 0.8783333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2012 - acc: 0.9421 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2043 - acc: 0.9470Micro f1 score: 0.8983333333333333\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2000 - acc: 0.9479 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2144 - acc: 0.9390Micro f1 score: 0.88\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1971 - acc: 0.9464 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1954 - acc: 0.9456Micro f1 score: 0.8866666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2013 - acc: 0.9421 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1907 - acc: 0.9456Micro f1 score: 0.8916666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1913 - acc: 0.9457 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1794 - acc: 0.9556Micro f1 score: 0.9016666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1827 - acc: 0.9514 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1812 - acc: 0.9567Micro f1 score: 0.895\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1746 - acc: 0.9564 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1590 - acc: 0.9511Micro f1 score: 0.8916666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1682 - acc: 0.9564 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1639 - acc: 0.9589Micro f1 score: 0.8883333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1678 - acc: 0.9564 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1543 - acc: 0.9600Micro f1 score: 0.8866666666666667\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1689 - acc: 0.9571 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1649 - acc: 0.9567Micro f1 score: 0.8916666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1659 - acc: 0.9593 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1609 - acc: 0.9633Micro f1 score: 0.8966666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1606 - acc: 0.9607 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1520 - acc: 0.9678Micro f1 score: 0.895\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1566 - acc: 0.9593 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1555 - acc: 0.9600Micro f1 score: 0.9\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1527 - acc: 0.9550 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1319 - acc: 0.9656Micro f1 score: 0.9\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1526 - acc: 0.9586 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1513 - acc: 0.9550Micro f1 score: 0.9\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1520 - acc: 0.9536 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1443 - acc: 0.9660Micro f1 score: 0.8816666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1445 - acc: 0.9657 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1390 - acc: 0.9600Micro f1 score: 0.8916666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1447 - acc: 0.9579 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1362 - acc: 0.9622Micro f1 score: 0.8916666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1422 - acc: 0.9629 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1406 - acc: 0.9689Micro f1 score: 0.9\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1346 - acc: 0.9679 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1387 - acc: 0.9667Micro f1 score: 0.92\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1341 - acc: 0.9671 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1305 - acc: 0.9744Micro f1 score: 0.9083333333333333\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1296 - acc: 0.9714 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1256 - acc: 0.9778Micro f1 score: 0.9133333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1202 - acc: 0.9743 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1268 - acc: 0.9744Micro f1 score: 0.91\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1213 - acc: 0.9743 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1045 - acc: 0.9789Micro f1 score: 0.9166666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1159 - acc: 0.9743 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1162 - acc: 0.9760Micro f1 score: 0.9116666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1100 - acc: 0.9779 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1144 - acc: 0.9770Micro f1 score: 0.915\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1086 - acc: 0.9764 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1195 - acc: 0.9744Micro f1 score: 0.925\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1093 - acc: 0.9771 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1057 - acc: 0.9760Micro f1 score: 0.915\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1051 - acc: 0.9764 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1054 - acc: 0.9780Micro f1 score: 0.92\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1069 - acc: 0.9771 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1052 - acc: 0.9822Micro f1 score: 0.915\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1043 - acc: 0.9793 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1054 - acc: 0.9740Micro f1 score: 0.905\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1008 - acc: 0.9786 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1074 - acc: 0.9756Micro f1 score: 0.9066666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1159 - acc: 0.9700 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1194 - acc: 0.9722Micro f1 score: 0.91\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1106 - acc: 0.9736 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1072 - acc: 0.9720Micro f1 score: 0.9166666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1090 - acc: 0.9679 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1067 - acc: 0.9750Micro f1 score: 0.9166666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1078 - acc: 0.9736 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1062 - acc: 0.9760Micro f1 score: 0.9166666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1042 - acc: 0.9771 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0916 - acc: 0.9760Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0974 - acc: 0.9771 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0956 - acc: 0.9780Micro f1 score: 0.9116666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1015 - acc: 0.9779 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0920 - acc: 0.9790Micro f1 score: 0.92\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0948 - acc: 0.9793 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0963 - acc: 0.9770Micro f1 score: 0.92\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0981 - acc: 0.9764 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0817 - acc: 0.9856Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0791 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0848 - acc: 0.9844Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0815 - acc: 0.9857 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0845 - acc: 0.9860Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0809 - acc: 0.9857 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0776 - acc: 0.9870Micro f1 score: 0.92\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0748 - acc: 0.9886 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0766 - acc: 0.9850Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0778 - acc: 0.9829 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0856 - acc: 0.9778Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0784 - acc: 0.9814 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0712 - acc: 0.9870Micro f1 score: 0.9216666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0740 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0711 - acc: 0.9860Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0740 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0744 - acc: 0.9800Micro f1 score: 0.9233333333333333\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0739 - acc: 0.9821 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0714 - acc: 0.9833Micro f1 score: 0.9116666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0732 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0721 - acc: 0.9880Micro f1 score: 0.925\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0796 - acc: 0.9857 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0804 - acc: 0.9850Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0801 - acc: 0.9836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0722 - acc: 0.9850Micro f1 score: 0.92\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0730 - acc: 0.9850 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0637 - acc: 0.9922Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0707 - acc: 0.9893 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0624 - acc: 0.9900Micro f1 score: 0.925\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0643 - acc: 0.9886 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0623 - acc: 0.9878Micro f1 score: 0.9233333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0716 - acc: 0.9836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0552 - acc: 0.9890Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0688 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0670 - acc: 0.9870Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0650 - acc: 0.9864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0566 - acc: 0.9878Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0664 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0656 - acc: 0.9850Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0609 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0638 - acc: 0.9870Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0683 - acc: 0.9821 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0591 - acc: 0.9822Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0645 - acc: 0.9836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0615 - acc: 0.9880Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0622 - acc: 0.9886 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0682 - acc: 0.9844Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0644 - acc: 0.9850 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0638 - acc: 0.9840Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0669 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0721 - acc: 0.9860Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0715 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0675 - acc: 0.9850Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0680 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0684 - acc: 0.9844Micro f1 score: 0.925\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0730 - acc: 0.9836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0662 - acc: 0.9800Micro f1 score: 0.93\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0737 - acc: 0.9793 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0628 - acc: 0.9867Micro f1 score: 0.915\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0722 - acc: 0.9821 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0622 - acc: 0.9889Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0642 - acc: 0.9893 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0609 - acc: 0.9800Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0681 - acc: 0.9807 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0583 - acc: 0.9887Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0562 - acc: 0.9886 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0553 - acc: 0.9878Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0527 - acc: 0.9893 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0527 - acc: 0.9910Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0545 - acc: 0.9893 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0562 - acc: 0.9840Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0554 - acc: 0.9857 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0560 - acc: 0.9900Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0563 - acc: 0.9900 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0648 - acc: 0.9830Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0605 - acc: 0.9836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0526 - acc: 0.9890Micro f1 score: 0.9216666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0572 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0620 - acc: 0.9844Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0577 - acc: 0.9864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0550 - acc: 0.9880Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0622 - acc: 0.9857 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0619 - acc: 0.9830Micro f1 score: 0.9216666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0638 - acc: 0.9821 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0497 - acc: 0.9944Micro f1 score: 0.9233333333333333\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0555 - acc: 0.9907 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0489 - acc: 0.9900Micro f1 score: 0.94\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0549 - acc: 0.9900 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0628 - acc: 0.9850Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0624 - acc: 0.9864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0550 - acc: 0.9889Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0586 - acc: 0.9850 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0758 - acc: 0.9822Micro f1 score: 0.9233333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0771 - acc: 0.9793 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0851 - acc: 0.9744Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0838 - acc: 0.9736 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0667 - acc: 0.9850Micro f1 score: 0.9183333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0702 - acc: 0.9829 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0665 - acc: 0.9822Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0636 - acc: 0.9850 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0587 - acc: 0.9878Micro f1 score: 0.93\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0551 - acc: 0.9864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0441 - acc: 0.9922Micro f1 score: 0.9266666666666666\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0467 - acc: 0.9914 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0408 - acc: 0.9940Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0452 - acc: 0.9914 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0533 - acc: 0.9900Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0464 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0454 - acc: 0.9900Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0480 - acc: 0.9900 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0504 - acc: 0.9922Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0514 - acc: 0.9921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0426 - acc: 0.9890Micro f1 score: 0.925\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0452 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0366 - acc: 0.9933Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0425 - acc: 0.9907 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0416 - acc: 0.9911Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0407 - acc: 0.9921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0401 - acc: 0.9950Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0391 - acc: 0.9943 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0299 - acc: 0.9956Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0356 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0292 - acc: 0.9962Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0349 - acc: 0.9921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0328 - acc: 0.9950Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0314 - acc: 0.9957 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0296 - acc: 0.9989Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0321 - acc: 0.9964 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0332 - acc: 0.9950Micro f1 score: 0.93\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0356 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0351 - acc: 0.9930Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0381 - acc: 0.9914 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0400 - acc: 0.9878Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0397 - acc: 0.9886 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0359 - acc: 0.9940Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0364 - acc: 0.9943 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0359 - acc: 0.9922Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0354 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0389 - acc: 0.9911Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0426 - acc: 0.9893 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0428 - acc: 0.9900Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0448 - acc: 0.9900 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0541 - acc: 0.9911Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0552 - acc: 0.9900 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0414 - acc: 0.9911Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0452 - acc: 0.9893 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0615 - acc: 0.9833Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0579 - acc: 0.9843 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0545 - acc: 0.9867Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0541 - acc: 0.9864 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0578 - acc: 0.9856Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0550 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0373 - acc: 0.9930Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0495 - acc: 0.9871 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0466 - acc: 0.9900Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0597 - acc: 0.9821 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0739 - acc: 0.9744Micro f1 score: 0.9216666666666666\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0718 - acc: 0.9750 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0821 - acc: 0.9730Micro f1 score: 0.93\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0755 - acc: 0.9750 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0670 - acc: 0.9833Micro f1 score: 0.9316666666666665\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0673 - acc: 0.9836 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0579 - acc: 0.9830Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0629 - acc: 0.9807 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0519 - acc: 0.9900Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0510 - acc: 0.9907 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 178/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0478 - acc: 0.9878Micro f1 score: 0.925\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0450 - acc: 0.9886 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0452 - acc: 0.9922Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0418 - acc: 0.9921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0384 - acc: 0.9910Micro f1 score: 0.9433333333333332\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0375 - acc: 0.9921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0357 - acc: 0.9900Micro f1 score: 0.9233333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0316 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0354 - acc: 0.9922Micro f1 score: 0.9433333333333332\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0310 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0331 - acc: 0.9911Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0304 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0333 - acc: 0.9944Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0301 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0289 - acc: 0.9956Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0274 - acc: 0.9964 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0263 - acc: 0.9950Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0258 - acc: 0.9964 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0237 - acc: 0.9962Micro f1 score: 0.9283333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0276 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0247 - acc: 0.9978Micro f1 score: 0.9366666666666666\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0277 - acc: 0.9964 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0289 - acc: 0.9944Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0277 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0254 - acc: 0.9970Micro f1 score: 0.94\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0260 - acc: 0.9964 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0275 - acc: 0.9944Micro f1 score: 0.935\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0269 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0291 - acc: 0.9944Micro f1 score: 0.9333333333333333\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0313 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0342 - acc: 0.9944Micro f1 score: 0.945\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0343 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0351 - acc: 0.9933Micro f1 score: 0.9466666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0326 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0323 - acc: 0.9922Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0322 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0344 - acc: 0.9911Micro f1 score: 0.94\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0297 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0268 - acc: 0.9944Micro f1 score: 0.9483333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0331 - acc: 0.9936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0229 - acc: 0.9933Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0285 - acc: 0.9921 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0191 - acc: 0.9967Micro f1 score: 0.9416666666666667\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0213 - acc: 0.9964 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0174 - acc: 0.9989Micro f1 score: 0.9383333333333334\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0186 - acc: 0.9971 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe21f5361d0>"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "class Metrics2(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "      self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      val_predict = (np.asarray(self.model.predict(X_test_spectrogram))).round()\n",
    "      \n",
    "      digit_predict=[]\n",
    "      \n",
    "      for i in val_predict:\n",
    "        digit_predict.append(np.argmax(i))\n",
    "      \n",
    "      val_targ = y_test\n",
    "      f1 = f1_score(val_targ, digit_predict,average='micro')\n",
    "      self.val_f1s.append(f1)\n",
    "      print(\"Micro f1 score:\",f1)\n",
    "        \n",
    "metrics2 = Metrics2()\n",
    "\n",
    "model2.fit(x=X_train_spectrogram,\n",
    "           y=y_train,\n",
    "           epochs=200,\n",
    "           batch_size=100,\n",
    "           callbacks=[tensorboard,metrics2],\n",
    "           validation_data=[X_test_spectrogram,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2p8DOh3m4mlF"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/drive/MyDrive/Spoken_digit_assignment/model2_logs/20210728-105556/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSl8ZOXjaNqJ"
   },
   "source": [
    "### 3. data augmentation  \n",
    "<pre>\n",
    "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
    "\n",
    "There are two types of augmentation:\n",
    "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
    "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "jR4JSEDgaNqK"
   },
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path,get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "QRdefb-SaNqS"
   },
   "outputs": [],
   "source": [
    "temp_path = df_audio.iloc[0].path\n",
    "aug_temp = generate_augmented_data(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzdG3iS-aNqc",
    "outputId": "dbaeab02-07a3-4795-92ad-3e2ae31b76a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckytZsraNqk"
   },
   "source": [
    "As discussed above, for one data point, we will get 9 augmented data points.  \n",
    "\n",
    "Split data into train and test (80-20 split)\n",
    "\n",
    "We have 2000 data points(1600 train points, 400 test points) \n",
    "\n",
    "Do augmentation only on train data, after augmentation we will get 14400 train points. \n",
    "\n",
    "do the above steps i.e training with raw data and spectrogram data with augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdKXVRlpaNql"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "dir='/content/drive/MyDrive/Spoken_digit_assignment/recordings/'\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "for i in tqdm(all_files):\n",
    "  a=generate_augmented_data(dir+i)\n",
    "  for j in a:\n",
    "    X.append(j)\n",
    "  b=load_wav(dir+i)[0]\n",
    "  X.append(b)\n",
    "  for j in range(10):\n",
    "    Y.append(int(i.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "c5iioO-_6Dc5"
   },
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "4nl_QyB16EHm"
   },
   "outputs": [],
   "source": [
    "X_train_new,X_test_new,Y_train_new,Y_test_new=train_test_split(X,Y,test_size=0.2,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "nUFlg2V6_Rs_"
   },
   "outputs": [],
   "source": [
    "X_train_pad_seq_new= np.array(pad_sequences(X_train_new, dtype='float32', padding='post',maxlen=max_length))\n",
    "X_test_pad_seq_new= np.array(pad_sequences(X_test_new, dtype=\"float32\", padding='post', maxlen=max_length))\n",
    "\n",
    "X_train_mask_new= np.array([create_mask(i) for i in X_train_new],dtype=bool)\n",
    "X_test_mask_new= np.array([create_mask(i) for i in X_test_new],dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "jpOs9i7GAJYX"
   },
   "outputs": [],
   "source": [
    "In=Input(shape=(max_length,1))\n",
    "In2=Input(shape=(max_length),dtype=bool)\n",
    "LS=LSTM(50)(In,mask=In2)\n",
    "D1=Dense(32,activation='relu')(LS)\n",
    "OUT=Dense(10,activation='softmax')(D1)\n",
    "model3=Model(inputs=([In,In2]),outputs=OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "BKzpl6HXAYYv"
   },
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "      self.val_f1 = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      val_predict = (np.asarray(self.model.predict([X_test_pad_seq_new,X_test_mask_new]))).round()\n",
    "      \n",
    "      digit_predict=[]\n",
    "      \n",
    "      for i in val_predict:\n",
    "        digit_predict.append(np.argmax(i))\n",
    "      val_targ = Y_test_new\n",
    "      \n",
    "      f1 = f1_score(val_targ, digit_predict,average='micro')\n",
    "      \n",
    "      self.val_f1.append(f1)\n",
    "      \n",
    "      print(\" Micro_f1_score:\",f1)\n",
    "        \n",
    "metrics = Metrics()\n",
    "logdir='/content/drive/MyDrive/Spoken_digit_assignment/model3_logs/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir,)\n",
    " \n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_acc',mode='max',patience=2)\n",
    "\n",
    "optim=tf.keras.optimizers.Adam()\n",
    "\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model3.compile(optimizer=optim,loss=loss,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "VemGwFpnBA_W"
   },
   "outputs": [],
   "source": [
    "X_train_full=[X_train_pad_seq_new,X_train_mask_new]\n",
    "\n",
    "X_test_full=[X_test_pad_seq_new,X_test_mask_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aix_otHjCEXu",
    "outputId": "4d963279-4489-4adf-fa26-d6396fc860d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731    /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "1693    /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "610     /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "1966    /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "518     /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "                              ...                        \n",
       "650     /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "873     /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "787     /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "918     /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "1863    /content/drive/MyDrive/Spoken_digit_assignment...\n",
       "Name: path, Length: 600, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMAm_Mx-AsPf",
    "outputId": "2b41f877-032c-4223-cead-25856dd0e78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 2.3027 - acc: 0.0973 Micro_f1_score: 0.10000000000000002\n",
      "160/160 [==============================] - 151s 945ms/step - loss: 2.3027 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1909dc950>"
      ]
     },
     "execution_count": 183,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train_full,Y_train_new,validation_data=[X_test_full,Y_test_new],epochs=1,batch_size=100,\n",
    "          callbacks=[tensorboard,early_stopping,metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "JAzvjhkEBZwv"
   },
   "outputs": [],
   "source": [
    "X_train_spectrogram_new=[]\n",
    "for i in X_train_pad_seq_new:\n",
    "  X_train_spectrogram_new.append(convert_to_spectrogram(i))\n",
    "X_train_spectrogram_new=np.array(X_train_spectrogram_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "UHnLwumsFte_"
   },
   "outputs": [],
   "source": [
    "X_test_spectrogram_new=[]\n",
    "for i in X_test_pad_seq_new:\n",
    "  X_test_spectrogram_new.append(convert_to_spectrogram(i))\n",
    "X_test_spectrogram_new=np.array(X_test_spectrogram_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "L2oUSgKMEaIZ"
   },
   "outputs": [],
   "source": [
    "logdir='/content/drive/MyDrive/Spoken_digit_assignment/model4_logs/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir,)\n",
    "\n",
    "class Metrics2(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "      self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      val_predict = (np.asarray(self.model.predict(X_test_spectrogram_new))).round()\n",
    "      \n",
    "      digit_predict=[]\n",
    "      \n",
    "      for i in val_predict:\n",
    "        digit_predict.append(np.argmax(i))\n",
    "      \n",
    "      val_targ = Y_test_new\n",
    "      f1 = f1_score(val_targ, digit_predict,average='micro')\n",
    "      self.val_f1s.append(f1)\n",
    "      print(\"Micro f1 score:\",f1)\n",
    "        \n",
    "metrics2 = Metrics2()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "-MrXayT7FG7u"
   },
   "outputs": [],
   "source": [
    "In=Input(shape=(64,35,))\n",
    "\n",
    "LS=LSTM(units=100,return_sequences=True)(In)\n",
    "\n",
    "output=tf.keras.layers.Reshape(target_shape=(64,100,1))(LS)\n",
    "\n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAveragePooling1D())(output)\n",
    "\n",
    "output=tf.keras.layers.Reshape(target_shape=(64,))(output)\n",
    "\n",
    "output=Dense(128,activation='relu')(output)\n",
    "\n",
    "output=Dense(64,activation='relu')(output)\n",
    "\n",
    "predict=Dense(10,activation='softmax')(output)\n",
    "\n",
    "model4=Model(inputs=In,outputs=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "7eXesDcmFKDI"
   },
   "outputs": [],
   "source": [
    "optim=tf.keras.optimizers.Adam()\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model4.compile(optimizer=optim,loss=loss,metrics=['acc'])\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_acc',patience=3,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4WusiSPFRoz",
    "outputId": "b2706e78-1b93-4849-cd9a-140e2a61b837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/160 [..............................] - ETA: 8s - loss: 2.2996 - acc: 0.1700WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0914s). Check your callbacks.\n",
      "152/160 [===========================>..] - ETA: 0s - loss: 1.4999 - acc: 0.4770Micro f1 score: 0.51825\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.4723 - acc: 0.4869 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.7097 - acc: 0.7551Micro f1 score: 0.7295\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.7097 - acc: 0.7551 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.5325 - acc: 0.8150Micro f1 score: 0.7935\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.5293 - acc: 0.8163 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8478Micro f1 score: 0.8289999999999998\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.4434 - acc: 0.8474 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8693Micro f1 score: 0.8525\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3856 - acc: 0.8690 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.3489 - acc: 0.8835Micro f1 score: 0.86675\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3471 - acc: 0.8841 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.8949Micro f1 score: 0.86125\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3179 - acc: 0.8946 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.3035 - acc: 0.9011Micro f1 score: 0.878\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3034 - acc: 0.9009 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.2758 - acc: 0.9106Micro f1 score: 0.89425\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2750 - acc: 0.9110 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.2585 - acc: 0.9161Micro f1 score: 0.89675\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2581 - acc: 0.9166 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.2574 - acc: 0.9188Micro f1 score: 0.90125\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2562 - acc: 0.9190 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "152/160 [===========================>..] - ETA: 0s - loss: 0.2341 - acc: 0.9237Micro f1 score: 0.91\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2332 - acc: 0.9239 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9286Micro f1 score: 0.91225\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2222 - acc: 0.9285 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9304Micro f1 score: 0.91175\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2201 - acc: 0.9306 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2107 - acc: 0.9331Micro f1 score: 0.9215\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2107 - acc: 0.9331 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "152/160 [===========================>..] - ETA: 0s - loss: 0.1964 - acc: 0.9362Micro f1 score: 0.9265\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1965 - acc: 0.9366 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.1888 - acc: 0.9395Micro f1 score: 0.91575\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1882 - acc: 0.9399 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1764 - acc: 0.9468Micro f1 score: 0.93025\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1775 - acc: 0.9465 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1783 - acc: 0.9427Micro f1 score: 0.92675\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1763 - acc: 0.9433 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9465Micro f1 score: 0.9315\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1719 - acc: 0.9463 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9459Micro f1 score: 0.92\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1675 - acc: 0.9462 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9490Micro f1 score: 0.9325\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1629 - acc: 0.9488 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1530 - acc: 0.9508Micro f1 score: 0.9355\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1537 - acc: 0.9507 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.1574 - acc: 0.9501Micro f1 score: 0.93775\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1563 - acc: 0.9506 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9501Micro f1 score: 0.92725\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1546 - acc: 0.9501 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9526Micro f1 score: 0.94225\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1496 - acc: 0.9530 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9560Micro f1 score: 0.94225\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1364 - acc: 0.9562 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.1377 - acc: 0.9569Micro f1 score: 0.9425\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1377 - acc: 0.9569 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1291 - acc: 0.9593Micro f1 score: 0.94\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1301 - acc: 0.9592 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1306 - acc: 0.9565Micro f1 score: 0.94625\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1304 - acc: 0.9571 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9574Micro f1 score: 0.94425\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1311 - acc: 0.9576 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9606Micro f1 score: 0.94175\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1280 - acc: 0.9604 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9591Micro f1 score: 0.95075\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1231 - acc: 0.9589 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1217 - acc: 0.9610Micro f1 score: 0.9375\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1233 - acc: 0.9601 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9617Micro f1 score: 0.95425\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1172 - acc: 0.9618 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1145 - acc: 0.9637Micro f1 score: 0.948\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1140 - acc: 0.9639 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1208 - acc: 0.9624Micro f1 score: 0.9455\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1211 - acc: 0.9621 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "152/160 [===========================>..] - ETA: 0s - loss: 0.1071 - acc: 0.9649Micro f1 score: 0.95325\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1072 - acc: 0.9647 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9640Micro f1 score: 0.954\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1083 - acc: 0.9641 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.1036 - acc: 0.9662Micro f1 score: 0.93975\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1049 - acc: 0.9656 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.1109 - acc: 0.9642Micro f1 score: 0.95075\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1111 - acc: 0.9639 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9650Micro f1 score: 0.9485\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1089 - acc: 0.9646 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9655Micro f1 score: 0.9565\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1064 - acc: 0.9656 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.1032 - acc: 0.9659Micro f1 score: 0.94225\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1037 - acc: 0.9659 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9633Micro f1 score: 0.95425\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1060 - acc: 0.9634 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9687Micro f1 score: 0.96075\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0941 - acc: 0.9686 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9699Micro f1 score: 0.9585\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0935 - acc: 0.9701 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9674Micro f1 score: 0.95825\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0989 - acc: 0.9671 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9719Micro f1 score: 0.95725\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0888 - acc: 0.9719 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "152/160 [===========================>..] - ETA: 0s - loss: 0.0945 - acc: 0.9687Micro f1 score: 0.95625\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0951 - acc: 0.9682 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0967 - acc: 0.9690Micro f1 score: 0.96025\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0961 - acc: 0.9692 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9737Micro f1 score: 0.9595\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0818 - acc: 0.9739 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.0796 - acc: 0.9737Micro f1 score: 0.953\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0788 - acc: 0.9741 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9691Micro f1 score: 0.955\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0884 - acc: 0.9692 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9701Micro f1 score: 0.96125\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0863 - acc: 0.9701 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9734Micro f1 score: 0.956\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0826 - acc: 0.9732 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9728Micro f1 score: 0.95725\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0801 - acc: 0.9728 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9691Micro f1 score: 0.94875\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0876 - acc: 0.9692 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9729Micro f1 score: 0.95825\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0840 - acc: 0.9732 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.0768 - acc: 0.9751Micro f1 score: 0.96325\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0767 - acc: 0.9749 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9736Micro f1 score: 0.96625\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0764 - acc: 0.9734 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0797 - acc: 0.9728Micro f1 score: 0.9615\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0797 - acc: 0.9728 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0829 - acc: 0.9727Micro f1 score: 0.963\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0821 - acc: 0.9731 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9750Micro f1 score: 0.95575\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0744 - acc: 0.9754 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9706Micro f1 score: 0.961\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0851 - acc: 0.9706 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9754Micro f1 score: 0.9617499999999999\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0748 - acc: 0.9755 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9728Micro f1 score: 0.9645\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0797 - acc: 0.9729 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "153/160 [===========================>..] - ETA: 0s - loss: 0.0767 - acc: 0.9724Micro f1 score: 0.9585\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0768 - acc: 0.9722 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9781Micro f1 score: 0.95875\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0704 - acc: 0.9779 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0762 - acc: 0.9735Micro f1 score: 0.9635\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0758 - acc: 0.9737 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0675 - acc: 0.9767Micro f1 score: 0.95425\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0675 - acc: 0.9767 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "157/160 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9714Micro f1 score: 0.9514999999999999\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0789 - acc: 0.9714 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9756Micro f1 score: 0.9665\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0705 - acc: 0.9754 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0744 - acc: 0.9757Micro f1 score: 0.96275\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0736 - acc: 0.9761 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9729Micro f1 score: 0.96125\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0753 - acc: 0.9729 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9743Micro f1 score: 0.9605\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0713 - acc: 0.9744 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9777Micro f1 score: 0.96225\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0666 - acc: 0.9776 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9767Micro f1 score: 0.969\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0695 - acc: 0.9767 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9794Micro f1 score: 0.96875\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0610 - acc: 0.9795 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9792Micro f1 score: 0.9675\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0610 - acc: 0.9793 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9780Micro f1 score: 0.9565\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0633 - acc: 0.9778 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0633 - acc: 0.9776Micro f1 score: 0.96625\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0634 - acc: 0.9775 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "152/160 [===========================>..] - ETA: 0s - loss: 0.0680 - acc: 0.9753Micro f1 score: 0.9715\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0670 - acc: 0.9759 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0572 - acc: 0.9810Micro f1 score: 0.968\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0572 - acc: 0.9810 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "157/160 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9808Micro f1 score: 0.95925\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0615 - acc: 0.9807 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0659 - acc: 0.9768Micro f1 score: 0.966\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0658 - acc: 0.9769 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9775Micro f1 score: 0.96575\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0676 - acc: 0.9772 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9785Micro f1 score: 0.96725\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0602 - acc: 0.9785 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9807Micro f1 score: 0.97\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0579 - acc: 0.9808 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9816Micro f1 score: 0.97075\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0565 - acc: 0.9816 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9806Micro f1 score: 0.968\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0556 - acc: 0.9807 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "156/160 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9798Micro f1 score: 0.9505\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0597 - acc: 0.9798 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0671 - acc: 0.9768Micro f1 score: 0.965\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0674 - acc: 0.9767 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0614 - acc: 0.9784Micro f1 score: 0.96675\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0621 - acc: 0.9783 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.9817Micro f1 score: 0.96725\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0560 - acc: 0.9817 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9820Micro f1 score: 0.9665\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0562 - acc: 0.9814 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "155/160 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9828Micro f1 score: 0.95175\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0534 - acc: 0.9822 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "158/160 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9839Micro f1 score: 0.973\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0500 - acc: 0.9839 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "154/160 [===========================>..] - ETA: 0s - loss: 0.0449 - acc: 0.9853Micro f1 score: 0.96775\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0454 - acc: 0.9851 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "157/160 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9801Micro f1 score: 0.96825\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0535 - acc: 0.9804 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe18f4f4310>"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x=X_train_spectrogram_new,\n",
    "           y=Y_train_new,\n",
    "           epochs=100,\n",
    "           batch_size=100,\n",
    "           callbacks=[tensorboard,metrics2],\n",
    "           validation_data=[X_test_spectrogram_new,Y_test_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "9_eEv0BdF88J",
    "outputId": "a46f1952-8971-45c6-f944-5bebcbd92d5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>f1_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 1 (pad_seq+mask)</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model 2 (spectogram)</td>\n",
       "      <td>0.938333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model 3 (pad_seq+aug+mask)</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model 3 (aug spectogram)</td>\n",
       "      <td>0.968250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       models  f1_scores\n",
       "0      model 1 (pad_seq+mask)   0.100000\n",
       "1        model 2 (spectogram)   0.938333\n",
       "2  model 3 (pad_seq+aug+mask)   0.100000\n",
       "3    model 3 (aug spectogram)   0.968250"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models=['model 1 (pad_seq+mask)',\n",
    "         'model 2 (spectogram)',\n",
    "         'model 3 (pad_seq+aug+mask)',\n",
    "         'model 3 (aug spectogram)']\n",
    "\n",
    "scores=[ 0.10000000000000002,\n",
    "         0.9383333333333334,\n",
    "         0.10000000000000002,\n",
    "         0.96825]\n",
    "\n",
    "df=pd.DataFrame({'models':models,'f1_scores':scores})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pz8oPvH-JE4w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Speech detection Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
